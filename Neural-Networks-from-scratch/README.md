Implemented a simple neural network for classification with mini batch gradient descent.
Dataset: MNIST Handwritten digit images (0-9)
Training images: 60,000
Testing images: 10,000
Image size: 28x28

## Architecture 
### 1 hidden layer
### Loss function: Cross-entropy loss
### Activation function:
- Sigmoid (Hidden layer)
- Softmax (Output layer)
